{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Madison Mariani\n",
    " - Class\n",
    " - \n",
    " - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DS325, Gettysburg College, Professor Eatai Roth\n",
    "# Problem Set 1 - Linear Regression\n",
    "\n",
    "Due Friday Feb 13, 2025 11:30a\n",
    "\n",
    "Total pts: 20\n",
    "\n",
    "## IMPORTANT INSTRUCTIONS:\n",
    "\n",
    " - When you submit your code, make sure that every cell runs without returning an error.\n",
    " - Once you have the results you need, edit out any extraneous code and outputs.\n",
    " - Do not rewrite code if it doesn't need to be rewritten. For example, all the import statements you should need are in the first code block. Do not redo those in your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    " - Fit a linear regression model to the following synthetic data.\n",
    " - Calculate R^2 and MSE for your best fit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model(bias, Theta, X_names, model_name = None):\n",
    "    # A function to print the equation of a linear model\n",
    "    if model_name is None:\n",
    "        model_str = f'y ='\n",
    "    else:\n",
    "        model_str = f'{model_name}:\\n y ='\n",
    "\n",
    "    if not bias==0:\n",
    "        model_str += f' {bias:.2f}'\n",
    "        \n",
    "    for theta, x in zip(Theta, X_names):\n",
    "        if theta==0:\n",
    "            continue\n",
    "        else:\n",
    "            model_str+= f' + {theta:.2f}*{x}'\n",
    "    print(model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(15)\n",
    "bias = 20*np.random.randn()\n",
    "\n",
    "X, y, coef = make_regression(n_samples=300, \n",
    "                                   n_features=5,    # n_features = 5 --> simple linear regression\n",
    "                                   noise=10, \n",
    "                                   bias = bias, \n",
    "                                   random_state=5, \n",
    "                                   shuffle = False, # samples will be in order\n",
    "                                   coef = True) \n",
    "\n",
    "column_names = [f'x{n+1}' for n in range(X.shape[1])]\n",
    "reg_df = pd.DataFrame(data = X, \n",
    "             columns = column_names)\n",
    "reg_df['y'] = y\n",
    "\n",
    "reg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#Splitting the data into training and testing sets\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Create and fit model\n",
    "model_1 = LinearRegression()\n",
    "model_1.fit(X_train1, y_train1)\n",
    "\n",
    "y_pred_train1 = model_1.predict(X_train1)\n",
    "y_pred_test1 = model_1.predict(X_test1)\n",
    "\n",
    "R2_train1 = model_1.score(X_train1, y_train1)\n",
    "R2_test1 = model_1.score(X_test1, y_test1)\n",
    "\n",
    "MSE_train1 = mean_squared_error(y_train1, y_pred_train1)\n",
    "MSE_test1= mean_squared_error(y_test1, y_pred_test1)\n",
    "\n",
    "model_1.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training R^2: {R2_train1}\")\n",
    "print(f\"Testing R^2: {R2_test1}\")\n",
    "print(f\"Training MSE: {MSE_train1}\")\n",
    "print(f\"Testing MSE: {MSE_test1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your written answers here\n",
    "\n",
    "What are your model parameters?\n",
    " - Coefficients: 21.66685899, 21.18702903, 95.30151578,  6.82557851, 48.66087217\n",
    " - Intercept: -6.596397811498488\n",
    "\n",
    "What were your MSE and R^2?\n",
    " - Training:\n",
    "    - MSE: 89.30818326562368\n",
    "    - R^2: 0.9930926467162325\n",
    " - Testing:\n",
    "    - MSE: 123.74824982689078\n",
    "    - R^2: 0.991895578037526\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "Multiple Regression with Synthetic Data and Co-linearity\n",
    "\n",
    " - Show the correlation matrix for the 10 variables and the target variable.\n",
    " - Fit a linear regression model to the following synthetic data.\n",
    " - Calculate R^2 and MSE for your best fit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(15)\n",
    "bias = 50*np.random.randn()\n",
    "\n",
    "X, y, coef = sk.datasets.make_regression(n_samples=300, \n",
    "                                   n_features=9,    # n_features = 10 --> multiple linear regression\n",
    "                                   noise=3, \n",
    "                                   bias = bias, \n",
    "                                   n_informative = 6,\n",
    "                                   effective_rank = 6,\n",
    "                                   random_state=15, \n",
    "                                   shuffle = False, # samples will be in order\n",
    "                                   coef = True)\n",
    "\n",
    "Xa = (0.6*X[:, 2] + 0.4*X[:, 5]).reshape(-1, 1)\n",
    "X = np.hstack([X, Xa])\n",
    "coef = np.append(coef, 0)\n",
    "\n",
    "column_names = [f'x{n+1}' for n in range(X.shape[1])]\n",
    "reg2_df = pd.DataFrame(data = X, \n",
    "             columns = column_names)\n",
    "reg2_df['y'] = y\n",
    "\n",
    "print_model(bias, coef, column_names, model_name = 'True Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr2 = reg2_df.corr()\n",
    "\n",
    "sns.heatmap(corr2, annot=True, fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9)\n",
    "\n",
    "model_2 = LinearRegression()\n",
    "model_2.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model_2.predict(X_train)\n",
    "y_pred_test = model_2.predict(X_test)\n",
    "\n",
    "R2_train = model_2.score(X_train, y_train)\n",
    "R2_test = model_2.score(X_test, y_test)\n",
    "\n",
    "MSE_train = mean_squared_error(y_train, y_pred_train)\n",
    "MSE_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "print_model(bias, coef, column_names, model_name='True Model')\n",
    "print_model(model_2.intercept_, model_2.coef_, column_names, model_name='Model_2')\n",
    "print(f'R2_test: {R2_test: .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your written answers here\n",
    "\n",
    "What are your model parameters?\n",
    " - Coefficients: 5.82840868e+01  7.26733837e+01  4.44036870e+15  1.02191074e+01\n",
    "  5.78099172e+01  2.96024580e+15 -1.07157395e+01 -1.97611748e+00\n",
    " -1.08622601e+00 -7.40061450e+15\n",
    " - Intercept: -15.328673571423849\n",
    "\n",
    "Which features (x1, x2...) were significant? Which were co-linear?\n",
    "- Significant features:\n",
    "    - x1: Coefficient = \n",
    "    - x2: Coefficient = \n",
    "    - x4: Coefficient = \n",
    "    - x5: Coefficient = \n",
    "    - x7: Coefficient = \n",
    "    - x8: Coefficient = \n",
    "    - x9: Coefficient = \n",
    "- Co-linear features:\n",
    "    - x3\n",
    "    - x6\n",
    "    - x10\n",
    " \n",
    "What were your MSE and R^2?\n",
    " - Training:\n",
    "    - MSE: 9.600557347519077\n",
    "    - R^2: 0.8777950927207252\n",
    " - Testing:\n",
    "    - MSE: 9.435019344919324\n",
    "    - R^2: 0.806804417850224\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "For this problem, you'll using housing data from King County, Washington (included as kc_housing.csv).\n",
    "\n",
    "You should refer to the class notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.read_csv('kc_house_data.csv')\n",
    "housing_df.drop(columns= ['id', 'date', 'zipcode'], inplace=True)\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. \n",
    "\n",
    "**Do this part before part b and then don't go back and change your responses.**\n",
    "\n",
    "- Select three features to use for a multiple linear regression and justify your choices.\n",
    "- Use the StandardScalar to scale your features. Fit a linear regression using those three features. What is your $R^2$?\n",
    "- Plot predicted home values and actual home values, including a line representing perfect prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr =housing_df.corr()\n",
    "sns.heatmap(corr, annot=True, fmt= ' .1f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['sqft_living', 'grade', 'sqft_above']\n",
    "X = housing_df[features]\n",
    "y = housing_df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. \n",
    "- Create a training and testing data using all the features except for price (that's the target), date, and zipcode. Once you have the dataframe of your features, save a list of column labels, ```feature_names = x.columns```.\n",
    "- Use Lasso or Ridge regression to fit the model and calculate the $R^2$. Play around with $\\alpha$ until you get $R^2 > 0.65$. Keep in mind that price is in the range of \\$100k-3M and the scaled features will be in the range of -2 to 2, so $\\alpha$ should be a big number.\n",
    "- Get the coefficients of the Ridge or Lasso model; their order corresponds to the feature labels you saved earlier. Find the 3 biggest (absolute value) coefficients. Which features are they? Look up ```np.argsort()```; this function returns the indices of a list once it's been sorted. \n",
    "- Plot predicted vs actual home prices for the regularized model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_scaled_train = ss.fit_transform(X_train)\n",
    "X_scaled_test = ss.transform(X_test)\n",
    "\n",
    "model_lasso = Lasso(alpha=25,000)\n",
    "model_lasso.fit(X_scaled_train, y_train)\n",
    "\n",
    "R2_train =model_lasso.score(X_scaled_train, y_train)\n",
    "R2_test = model_lasso.score(X_scaled_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linreg = LinearRegression()\n",
    "model_linreg.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model_linreg.predict(X_scaled_train)\n",
    "y_test_pred = model_linreg.predict(X_scaled_test)\n",
    "\n",
    "R2_train = model_linreg.score(X_scaled_train, y_train)\n",
    "R2_test = model_linreg.score(X_scaled_test, y_test)\n",
    "MSE_train = mean_squared_error(y_train, y_train_pred)\n",
    "MSE_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "print(f\"Linear Regression - Training R²: {R2_train:.4f}\")\n",
    "print(f\"Linear Regression - Testing R²: {R2_test:.4f}\")\n",
    "print(f\"Linear Regression - Training MSE: {MSE_train:.4f}\")\n",
    "print(f\"Linear Regression - Testing MSE: {MSE_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lasso = Lasso(alpha=.7)  # You can adjust alpha value\n",
    "model_lasso.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_train_lasso = model_lasso.score(X_train_scaled, y_train)\n",
    "R2_test_lasso = model_lasso.score(X_test_scaled, y_test)\n",
    "\n",
    "MSE_train_lasso = mean_squared_error(y_train, model_lasso.predict(X_train_scaled))\n",
    "MSE_test_lasso = mean_squared_error(y_test, model_lasso.predict(X_test_scaled))\n",
    "\n",
    "print(f\"Lasso Regression - Training R²: {R2_train_lasso:.4f}\")\n",
    "print(f\"Lasso Regression - Testing R²: {R2_test_lasso:.4f}\")\n",
    "print(f\"Lasso Regression - Training MSE: {MSE_train_lasso:.4f}\")\n",
    "print(f\"Lasso Regression - Testing MSE: {MSE_test_lasso:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your written answers here\n",
    "Which features are you using and why?\n",
    "- sqft_living: square footage is important because larger homes have higher prices\n",
    "-  bedrooms: # of bedrooms in the house is important in determining price\n",
    "- bathrooms: # of bathrooms influences the price of a home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your written answers here\n",
    "Which regression did you use?\n",
    " - Lasso\n",
    "\n",
    "Does your regularized model look better than your MLR? How so?\n",
    " - Testing R^2 for MLR: 0.5060\n",
    " - Testing MSE for MLR: 42317505195.9631\n",
    " - Testing R^2 for Lasso: 0.5060\n",
    " - Testing MSE for Lasso: 42317505195.9631\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.\n",
    "It seems that our model over-valuates houses in the higher price range.\n",
    " - Split the data into homes below and above $1M sale price. \n",
    " - Fit a Lasso or Ridge model to each of the split data sets.\n",
    " - Plot predicted vs actual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Your written answers>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Your written answers here\n",
    "\n",
    " What are the $R^2$ for the two models?\n",
    "  - R^2 for homes below $1M:\n",
    "  - R^2 for homes above $1M:\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
